{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detrended Fluctuation Analysis\n",
    "\n",
    "https://github.com/CSchoel/nolds/blob/master/nolds/measures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import warnings\n",
    "from entropy import utils\n",
    "\n",
    "from nolds import dfa\n",
    "\n",
    "warnings.simplefilter('ignore', np.RankWarning)\n",
    "\n",
    "np.random.seed(1234567)\n",
    "x = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logarithmic_n(min_n, max_n, factor):\n",
    "    \"\"\"\n",
    "    Creates a list of values by successively multiplying a minimum value min_n by\n",
    "    a factor > 1 until a maximum value max_n is reached.\n",
    "    Non-integer results are rounded down.\n",
    "    Args:\n",
    "    min_n (float):\n",
    "      minimum value (must be < max_n)\n",
    "    max_n (float):\n",
    "      maximum value (must be > min_n)\n",
    "    factor (float):\n",
    "      factor used to increase min_n (must be > 1)\n",
    "    Returns:\n",
    "    list of integers:\n",
    "      min_n, min_n * factor, min_n * factor^2, ... min_n * factor^i < max_n\n",
    "      without duplicates\n",
    "    \"\"\"\n",
    "    assert max_n > min_n\n",
    "    assert factor > 1\n",
    "    # stop condition: min * f^x = max\n",
    "    # => f^x = max/min\n",
    "    # => x = log(max/min) / log(f)\n",
    "    max_i = int(np.floor(np.log(1.0 * max_n / min_n) / np.log(factor)))\n",
    "    ns = [min_n]\n",
    "    for i in range(max_i + 1):\n",
    "        n = int(np.floor(min_n * (factor ** i)))\n",
    "        if n > ns[-1]:\n",
    "            ns.append(n)\n",
    "    return ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfa2(x, nvals=None, overlap=False):\n",
    "    \"\"\"\n",
    "    Detrended fluctuation analysis (DFA).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list or np.array\n",
    "        One-dimensional time series.\n",
    "    nvals : list or np.array of int\n",
    "        subseries sizes at which to calculate fluctuation\n",
    "        (default: logarithmic_n(4, 0.1*len(data), 1.2))\n",
    "    overlap (boolean):\n",
    "        if True, the windows W_(n,i) will have a 50% overlap,\n",
    "        otherwise non-overlapping windows will be used\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dfa : float\n",
    "        the estimate alpha for the Hurst parameter (alpha < 1: stationary\n",
    "        process similar to fractional Gaussian noise with H = alpha,\n",
    "        alpha > 1: non-stationary process similar to fractional Brownian\n",
    "        motion with H = alpha - 1)\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Detrended fluctuation analysis, much like the Hurst exponent, is used to\n",
    "    find long-term statistical dependencies in time series.\n",
    "    \n",
    "    The idea behind DFA originates from the definition of self-affine\n",
    "    processes. A process X is said to be self-affine if the standard deviation\n",
    "    of the values within a window of length n changes with the window length\n",
    "    factor L in a power law:\n",
    "    \n",
    "    .. math:: std(X, L * n) = L^H * std(X, n)\n",
    "    \n",
    "    where std(X, k) is the standard deviation of the process X calculated over\n",
    "    windows of size k. In this equation, H is called the Hurst parameter, which\n",
    "    behaves indeed very similar to the Hurst exponent.\n",
    "    \n",
    "    Like the Hurst exponent, H can be obtained from a time series by\n",
    "    calculating std(X,n) for different n and fitting a straight line to the\n",
    "    plot of log(std(X,n)) versus log(n).\n",
    "    \n",
    "    To calculate a single std(X,n), the time series is split into windows of\n",
    "    equal length n, so that the ith window of this size has the form\n",
    "    \n",
    "    .. math:: W_(n,i) = [x_i, x_(i+1), x_(i+2), ... x_(i+n-1)]\n",
    "    \n",
    "    The value std(X,n) is then obtained by calculating std(W_(n,i)) for each i\n",
    "    and averaging the obtained values over i.\n",
    "    \n",
    "    The aforementioned definition of self-affinity, however, assumes that the\n",
    "    process is  non-stationary (i.e. that the standard deviation changes over\n",
    "    time) and it is highly influenced by local and global trends of the time\n",
    "    series.\n",
    "    \n",
    "    To overcome these problems, an estimate alpha of H is calculated by using a\n",
    "    \"walk\" or \"signal profile\" instead of the raw time series. This walk is\n",
    "    obtained by substracting the mean and then taking the cumulative sum of the\n",
    "    original time series. The local trends are removed for each window\n",
    "    separately by fitting a polynomial p_(n,i) to the window W_(n,i) and then\n",
    "    calculating W'_(n,i) = W_(n,i) - p_(n,i) (element-wise substraction).\n",
    "    We then calculate std(X,n) as before only using the \"detrended\" window\n",
    "    W'_(n,i) instead of W_(n,i). Instead of H we obtain the parameter alpha\n",
    "    from the line fitting.\n",
    "    \n",
    "    For alpha < 1 the underlying process is stationary and can be modelled as\n",
    "    fractional Gaussian noise with H = alpha. This means for alpha = 0.5 we\n",
    "    have no correlation or \"memory\", for 0.5 < alpha < 1 we have a memory with\n",
    "    positive correlation and for alpha < 0.5 the correlation is negative.\n",
    "    For alpha > 1 the underlying process is non-stationary and can be modeled\n",
    "    as fractional Brownian motion with H = alpha - 1.\n",
    "    \n",
    "    THE CODE AND DOCUMENTATION ARE ORIGINALLY FROM THE `NOLDS` PYTHON PACKAGE.\n",
    "    \n",
    "    References\n",
    "    ----------\n",
    "    .. [dfa_1] C.-K. Peng, S. V. Buldyrev, S. Havlin, M. Simons,\n",
    "               H. E. Stanley, and A. L. Goldberger, “Mosaic organization of\n",
    "               DNA nucleotides,” Physical Review E, vol. 49, no. 2, 1994.\n",
    "    .. [dfa_2] R. Hardstone, S.-S. Poil, G. Schiavone, R. Jansen,\n",
    "               V. V. Nikulin, H. D. Mansvelder, and K. Linkenkaer-Hansen,\n",
    "               “Detrended fluctuation analysis: A scale-free view on neuronal\n",
    "               oscillations,” Frontiers in Physiology, vol. 30, 2012.\n",
    "               \n",
    "    \n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    N = x.size\n",
    "    \n",
    "    if nvals is None:\n",
    "        nvals = np.array(logarithmic_n(4, 0.1 * N, 1.2))\n",
    "    \n",
    "    # create the signal profile\n",
    "    # (cumulative sum of deviations from the mean => \"walk\")\n",
    "    walk = np.cumsum(x - x.mean())\n",
    "    \n",
    "    fluctuations = np.zeros(nvals.size)\n",
    "    \n",
    "    for i_n, n in enumerate(nvals):\n",
    "        # subdivide data into chunks of size n\n",
    "        if overlap:\n",
    "            # step size n/2 instead of n\n",
    "            d = np.array([walk[i:i + n] for i in range(0, len(walk) - n, n // 2)])\n",
    "        else:\n",
    "            # non-overlapping windows => we can simply do a reshape\n",
    "            d = walk[:N - (N % n)]\n",
    "            d = d.reshape((N // n, n))\n",
    "        # calculate local trends as polynomes\n",
    "        ran_n = np.arange(n, dtype=np.float64)\n",
    "        ran_n_mean = ran_n.mean()\n",
    "        d_len = d.shape[0]\n",
    "        d_mean = d.mean(1)\n",
    "        slope = np.empty(d_len)\n",
    "        intercept = np.empty(d_len)\n",
    "        trend = np.empty((d_len, ran_n.size))\n",
    "        for i in range(d_len):\n",
    "            slope[i] = utils._slope_lstsq(ran_n, d[i])\n",
    "            intercept[i] = d_mean[i] - slope[i] * ran_n_mean\n",
    "            trend[i, :] = np.polyval([slope[i], intercept[i]], ran_n)\n",
    "            \n",
    "        # calculate standard deviation (\"fluctuation\") of walks in d around trend\n",
    "        flucs = np.sqrt(np.sum((d - trend) ** 2, axis=1) / n)\n",
    "        # calculate mean fluctuation over all subsequences\n",
    "        fluctuations[i_n] = flucs.sum() / flucs.size\n",
    "\n",
    "    # filter zeros from fluctuations\n",
    "    nonzero = np.nonzero(fluctuations)[0]\n",
    "    fluctuations = fluctuations[nonzero]\n",
    "    nvals = nvals[nonzero]\n",
    "\n",
    "    if len(fluctuations) == 0:\n",
    "        # all fluctuations are zero => we cannot fit a line\n",
    "        slope = np.nan\n",
    "    else:\n",
    "        slope = utils._slope_lstsq(np.log(nvals), np.log(fluctuations))\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5330608987017387\n",
      "0.5330608987017413\n"
     ]
    }
   ],
   "source": [
    "print(dfa(x, overlap=False))\n",
    "print(dfa2(x, overlap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5347468094425519\n",
      "0.5347468094425555\n"
     ]
    }
   ],
   "source": [
    "print(dfa(x, overlap=True))\n",
    "print(dfa2(x, overlap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 ms ± 753 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "14.6 ms ± 233 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dfa(x, overlap=False)\n",
    "%timeit dfa2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, log\n",
    "\n",
    "@numba.jit('i8[:](f8, f8, f8)', nopython=True)\n",
    "def log_n(min_n, max_n, factor):\n",
    "    max_i = int(floor(log(1.0 * max_n / min_n) / log(factor)))\n",
    "    ns = [min_n]\n",
    "    for i in range(max_i + 1):\n",
    "        n = int(floor(min_n * (factor ** i)))\n",
    "        if n > ns[-1]:\n",
    "            ns.append(n)\n",
    "    return np.array(ns, dtype=np.int64)\n",
    "\n",
    "@numba.jit('f8(f8[:])', nopython=True)\n",
    "def dfa3(x):\n",
    "    N = len(x)\n",
    "    nvals = log_n(4, 0.1 * N, 1.2)\n",
    "    walk = np.cumsum(x - x.mean())\n",
    "    fluctuations = np.zeros(len(nvals))\n",
    "    \n",
    "    for i_n, n in enumerate(nvals):\n",
    "        d = np.reshape(walk[:N - (N % n)], (N // n, n))\n",
    "        ran_n = np.array([float(na) for na in range(n)])\n",
    "        ran_n_mean = ran_n.mean()\n",
    "        d_len = len(d)\n",
    "        slope = np.empty(d_len)\n",
    "        intercept = np.empty(d_len)\n",
    "        trend = np.empty((d_len, ran_n.size))\n",
    "        for i in range(d_len):\n",
    "            sl = utils._slope_lstsq(ran_n, d[i])\n",
    "            di_mean = d[i].mean()\n",
    "            inter = di_mean - sl * ran_n_mean\n",
    "            slope[i] = sl\n",
    "            intercept[i] = inter\n",
    "            y = np.zeros_like(ran_n)\n",
    "            # Equivalent to np.polyval function\n",
    "            for p in [sl, inter]:\n",
    "                y = y * ran_n + p\n",
    "            trend[i, :] = y\n",
    "\n",
    "        # calculate standard deviation (\"fluctuation\") of walks in d around trend\n",
    "        flucs = np.sqrt(np.sum((d - trend) ** 2, axis=1) / n)\n",
    "        # calculate mean fluctuation over all subsequences\n",
    "        fluctuations[i_n] = flucs.sum() / flucs.size\n",
    "      \n",
    "    # Filter zero\n",
    "    nonzero = np.nonzero(fluctuations)[0]\n",
    "    fluctuations = fluctuations[nonzero]\n",
    "    nvals = nvals[nonzero]\n",
    "\n",
    "    if len(fluctuations) == 0:\n",
    "        # all fluctuations are zero => we cannot fit a line\n",
    "        dfa = np.nan\n",
    "    else:\n",
    "        dfa = utils._slope_lstsq(np.log(nvals), np.log(fluctuations))\n",
    "    return dfa   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5330608987017387\n",
      "0.5330608987017413\n",
      "0.5330608987017409\n"
     ]
    }
   ],
   "source": [
    "print(dfa(x, overlap=False))\n",
    "print(dfa2(x))\n",
    "print(dfa3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.6 ms ± 4.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "16 ms ± 335 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "800 µs ± 27.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dfa(x, overlap=False)\n",
    "%timeit dfa2(x, overlap=False)\n",
    "%timeit dfa3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.615840712681188\n",
      "1.6158407126811893\n",
      "1.6158407126811898\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234567)\n",
    "RANDOM_TS = np.random.rand(3000)\n",
    "SF_TS = 100\n",
    "PURE_SINE = np.sin(2 * np.pi * 1 * np.arange(3000) / 100)\n",
    "\n",
    "print(dfa(PURE_SINE, overlap=False))\n",
    "print(dfa2(PURE_SINE))\n",
    "print(dfa3(PURE_SINE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
